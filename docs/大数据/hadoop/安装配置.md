# 配置

---

**在安装目录下的etc/hadoop/文件夹**

- 配置**hadoop-env.sh** 文件

  `export JAVA_HOME=具体Java路径`

- 配置 **core-site.xml** 文件

  ```xml
  			<property>
           <name>fs.defaultFS</name>
            <value>hdfs://localhost:9000</value>
  			</property>
   
        <!-- 指定hadoop运行时产生文件的存储路径 -->
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/Users/ding/bigdata/hadoop-3.1.3/tmp</value>
        </property>
   
        <!-- hiveserver2连接时的设置,ding是当前用户 -->
        <property>
            <name>hadoop.proxyuser.ding.hosts</name>
            <value>*</value>
        </property>
   
        <property>
            <name>hadoop.proxyuser.ding.groups</name>
            <value>*</value>
        </property>
  ```

- 配置 **hdfs-site.xml** 文件

  ```xml
      <property>
          <!--指定hdfs保存数据副本的数量，包括自己，默认为3-->
          <!--伪分布式模式，此值必须为1-->
          <name>dfs.replication</name>
          <value>1</value>
      </property>
      
      <property>
          <name>dfs.namenode.name.dir</name>
          <!-- name node 存放 name table 的目录 -->
          <value>/Users/ding/bigdata/hadoop-3.1.3/tmp/hdfs/name</value>
      </property>
      
      <property>
          <name>dfs.datanode.data.dir</name>
          <!-- data node 存放数据 block 的目录 -->
          <value>/Users/ding/bigdata/hadoop-3.1.3/tmp/hdfs/data</value>
      </property>
  ```

- 配置 **mapred-site.xml** 文件

  ```xml
      <property>
  		<!--指定mapreduce运行在yarn上-->
          <name>mapreduce.framework.name</name>
          <value>yarn</value>
      </property>
  ```

- 配置 **yarn-site.xml** 文件

  ```xml
  		<property>
  			<!--NodeManager获取数据的方式-->
  			<name>yarn.nodemanager.aux-services</name>
  			<value>mapreduce_shuffle</value>
      </property>
  ```



# 启动

---

1. 第一次启动要初始化`hdfs namenode -format`
2. 启动集群`start-all.sh`，关闭集群`stop-all.sh`
3. 查看namenode地址localhost:9870（3版本是9870端口）

